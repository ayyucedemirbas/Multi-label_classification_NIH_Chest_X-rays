{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\ndef get_image_paths(directory):\n    image_paths = []\n    for subdir, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(\".png\"):\n                image_paths.append(os.path.join(subdir, file))\n    return image_paths\n\ndataset_directory = '/kaggle/input/data'\nimage_paths = get_image_paths(dataset_directory)\ncsv_file_path = '/kaggle/input/data/Data_Entry_2017.csv'\ndata_entry = pd.read_csv(csv_file_path)\n\nimage_name_to_path_dict = {os.path.basename(path): path for path in image_paths}\nfiltered_data_entry = data_entry[data_entry['Image Index'].isin(image_name_to_path_dict.keys())]\nfiltered_data_entry['Full Image Path'] = filtered_data_entry['Image Index'].apply(lambda x: image_name_to_path_dict[x])\n\nmlb = MultiLabelBinarizer()\nlabels_list = filtered_data_entry['Finding Labels'].str.split('|').tolist()\nencoded_labels = mlb.fit_transform(labels_list)\n\n# Create a DataFrame with image paths, labels, and patient IDs\ntf_dataset = pd.DataFrame({\n    'Image Path': filtered_data_entry['Full Image Path'],\n    'Label': list(encoded_labels),\n    'Patient ID': filtered_data_entry['Patient ID']\n})\n\n# Splitting the dataset based on Patient ID to avoid data leakage\nunique_patient_ids = tf_dataset['Patient ID'].unique()\nnp.random.seed(42)  # For reproducibility\nnp.random.shuffle(unique_patient_ids)\n\n# Use 80% of patients for training and 20% for validation\nsplit_idx = int(0.8 * len(unique_patient_ids))\ntrain_patient_ids = unique_patient_ids[:split_idx]\nvalidation_patient_ids = unique_patient_ids[split_idx:]\n\ntrain_df = tf_dataset[tf_dataset['Patient ID'].isin(train_patient_ids)]\nvalidation_df = tf_dataset[tf_dataset['Patient ID'].isin(validation_patient_ids)]\n\ndef parse_image(filename, label):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_png(image, channels=1)\n    image = tf.image.resize(image, [240, 240])\n    image = image / 255.0\n    label = tf.cast(label, dtype=tf.float32)\n    return image, label\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_df['Image Path'].values, np.vstack(train_df['Label'].values)))\ntrain_dataset = train_dataset.map(parse_image).shuffle(buffer_size=1000).batch(32)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((validation_df['Image Path'].values, np.vstack(validation_df['Label'].values)))\nvalidation_dataset = validation_dataset.map(parse_image).batch(32)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:00:55.787880Z","iopub.execute_input":"2023-12-27T19:00:55.788294Z","iopub.status.idle":"2023-12-27T19:01:59.432710Z","shell.execute_reply.started":"2023-12-27T19:00:55.788247Z","shell.execute_reply":"2023-12-27T19:01:59.431691Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:02:59.772245Z","iopub.execute_input":"2023-12-27T19:02:59.773117Z","iopub.status.idle":"2023-12-27T19:02:59.807516Z","shell.execute_reply.started":"2023-12-27T19:02:59.773085Z","shell.execute_reply":"2023-12-27T19:02:59.806392Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_labels = data_entry['Finding Labels'].str.split('|').explode().unique()\nnum_classes = len(all_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:02.026354Z","iopub.execute_input":"2023-12-27T19:03:02.026737Z","iopub.status.idle":"2023-12-27T19:03:02.368524Z","shell.execute_reply.started":"2023-12-27T19:03:02.026710Z","shell.execute_reply":"2023-12-27T19:03:02.367420Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"inputs= keras.Input(shape=(240, 240,1))\n\n\nx = Conv2D(128, kernel_size=(3, 3), activation='relu',padding='SAME')(inputs)\nx = Conv2D(128, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(128, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(128, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\nx = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='SAME')(inputs)\nx = Conv2D(64, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(64, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\nx = Conv2D(32, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(32, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(32, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(32, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\n\nx = Conv2D(16, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(16, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(16, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(16, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\nx = Flatten(name='flatten')(x)\nx = Dense(units=300, activation='relu')(x)\noutputs = Dense(units=num_classes, activation='sigmoid')(x)\nmodel= keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:03.531940Z","iopub.execute_input":"2023-12-27T19:03:03.532370Z","iopub.status.idle":"2023-12-27T19:03:03.969974Z","shell.execute_reply.started":"2023-12-27T19:03:03.532336Z","shell.execute_reply":"2023-12-27T19:03:03.969086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"all_labels","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:06.406664Z","iopub.execute_input":"2023-12-27T19:03:06.407052Z","iopub.status.idle":"2023-12-27T19:03:06.414728Z","shell.execute_reply.started":"2023-12-27T19:03:06.407022Z","shell.execute_reply":"2023-12-27T19:03:06.413764Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['Cardiomegaly', 'Emphysema', 'Effusion', 'No Finding', 'Hernia',\n       'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax',\n       'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema',\n       'Consolidation'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:09.534239Z","iopub.execute_input":"2023-12-27T19:03:09.535039Z","iopub.status.idle":"2023-12-27T19:03:09.542632Z","shell.execute_reply.started":"2023-12-27T19:03:09.535005Z","shell.execute_reply":"2023-12-27T19:03:09.541375Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n\ncsv_file_path = '/kaggle/input/data/Data_Entry_2017.csv'\ndata_entry = pd.read_csv(csv_file_path)\n\nlabels = data_entry['Finding Labels'].str.split('|').tolist()\n\nmlb = MultiLabelBinarizer()\nmlb.fit(labels)\n\nbinary_labels = mlb.transform(labels)\n\nclass_counts = binary_labels.sum(axis=0)\nn_samples = len(labels)\n\nclass_weights = (n_samples / class_counts)\n\nmin_weight = min(class_weights)\nclass_weights_normalized = class_weights / min_weight\n\nclass_weights = {i: weight for i, weight in enumerate(class_weights_normalized)}\n\nclass_weights\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:11.314577Z","iopub.execute_input":"2023-12-27T19:03:11.314976Z","iopub.status.idle":"2023-12-27T19:03:11.990686Z","shell.execute_reply.started":"2023-12-27T19:03:11.314945Z","shell.execute_reply":"2023-12-27T19:03:11.989668Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{0: 5.221991521757937,\n 1: 21.743876080691642,\n 2: 12.93357617313049,\n 3: 26.209726443768997,\n 4: 4.532627468649094,\n 5: 23.99085850556439,\n 6: 35.801304863582445,\n 7: 265.90748898678413,\n 8: 3.0341308937368052,\n 9: 10.439467312348668,\n 10: 1.0,\n 11: 9.534196809350814,\n 12: 17.831905465288035,\n 13: 42.18099231306779,\n 14: 11.384571859675594}"},"metadata":{}}]},{"cell_type":"code","source":"class_counts","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:13.800448Z","iopub.execute_input":"2023-12-27T19:03:13.800834Z","iopub.status.idle":"2023-12-27T19:03:13.807346Z","shell.execute_reply.started":"2023-12-27T19:03:13.800796Z","shell.execute_reply":"2023-12-27T19:03:13.806218Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([11559,  2776,  4667,  2303, 13317,  2516,  1686,   227, 19894,\n        5782, 60361,  6331,  3385,  1431,  5302])"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.BinaryCrossentropy(),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:15.667079Z","iopub.execute_input":"2023-12-27T19:03:15.667499Z","iopub.status.idle":"2023-12-27T19:03:15.690071Z","shell.execute_reply.started":"2023-12-27T19:03:15.667464Z","shell.execute_reply":"2023-12-27T19:03:15.689064Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_early_stopping():\n    \n    return tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n     \nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                                  patience=6, min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:17.643102Z","iopub.execute_input":"2023-12-27T19:03:17.644021Z","iopub.status.idle":"2023-12-27T19:03:17.649243Z","shell.execute_reply.started":"2023-12-27T19:03:17.643988Z","shell.execute_reply":"2023-12-27T19:03:17.648173Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:19.230877Z","iopub.execute_input":"2023-12-27T19:03:19.231616Z","iopub.status.idle":"2023-12-27T19:03:19.235710Z","shell.execute_reply.started":"2023-12-27T19:03:19.231584Z","shell.execute_reply":"2023-12-27T19:03:19.234786Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = \"./checkpoint\"\ncheckpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:21.030385Z","iopub.execute_input":"2023-12-27T19:03:21.031002Z","iopub.status.idle":"2023-12-27T19:03:21.036142Z","shell.execute_reply.started":"2023-12-27T19:03:21.030971Z","shell.execute_reply":"2023-12-27T19:03:21.035061Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"early_stopping = get_early_stopping()\n\ncallbacks = [checkpoint_callback, early_stopping, reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:22.760237Z","iopub.execute_input":"2023-12-27T19:03:22.761114Z","iopub.status.idle":"2023-12-27T19:03:22.765461Z","shell.execute_reply.started":"2023-12-27T19:03:22.761076Z","shell.execute_reply":"2023-12-27T19:03:22.764440Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=validation_dataset, batch_size=32, epochs=30,\n                    class_weight=class_weights, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:03:23.960232Z","iopub.execute_input":"2023-12-27T19:03:23.961177Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-12-27 19:03:26.605697: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"2803/2803 [==============================] - 1222s 428ms/step - loss: 1.6669 - accuracy: 0.1308 - val_loss: 0.2725 - val_accuracy: 0.1231 - lr: 0.0010\nEpoch 2/30\n2803/2803 [==============================] - 1200s 425ms/step - loss: 1.6161 - accuracy: 0.1730 - val_loss: 0.2757 - val_accuracy: 0.0736 - lr: 0.0010\nEpoch 3/30\n2803/2803 [==============================] - 1197s 425ms/step - loss: 1.6018 - accuracy: 0.1707 - val_loss: 0.2839 - val_accuracy: 0.0809 - lr: 0.0010\nEpoch 4/30\n2803/2803 [==============================] - 1203s 427ms/step - loss: 1.5965 - accuracy: 0.1860 - val_loss: 0.2719 - val_accuracy: 0.1195 - lr: 0.0010\nEpoch 5/30\n2803/2803 [==============================] - 1197s 424ms/step - loss: 1.5904 - accuracy: 0.1924 - val_loss: 0.2699 - val_accuracy: 0.1199 - lr: 0.0010\nEpoch 6/30\n2803/2803 [==============================] - 1195s 424ms/step - loss: 1.5838 - accuracy: 0.1940 - val_loss: 0.2732 - val_accuracy: 0.1026 - lr: 0.0010\nEpoch 7/30\n2797/2803 [============================>.] - ETA: 2s - loss: 1.5778 - accuracy: 0.1965","output_type":"stream"}]}]}