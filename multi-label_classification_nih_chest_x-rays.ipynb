{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\ndef get_image_paths(directory):\n    image_paths = []\n    for subdir, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(\".png\"):\n                image_paths.append(os.path.join(subdir, file))\n    return image_paths\n\ndataset_directory = '/kaggle/input/data'\nimage_paths = get_image_paths(dataset_directory)\ncsv_file_path = '/kaggle/input/data/Data_Entry_2017.csv'\ndata_entry = pd.read_csv(csv_file_path)\n\nimage_name_to_path_dict = {os.path.basename(path): path for path in image_paths}\nfiltered_data_entry = data_entry[data_entry['Image Index'].isin(image_name_to_path_dict.keys())]\nfiltered_data_entry['Full Image Path'] = filtered_data_entry['Image Index'].apply(lambda x: image_name_to_path_dict[x])\n\nmlb = MultiLabelBinarizer()\nlabels_list = filtered_data_entry['Finding Labels'].str.split('|').tolist()\nencoded_labels = mlb.fit_transform(labels_list)\n\ntf_dataset = pd.DataFrame({\n    'Image Path': filtered_data_entry['Full Image Path'],\n    'Label': list(encoded_labels),\n    'Patient ID': filtered_data_entry['Patient ID']\n})\n\n# Splitting the dataset based on Patient ID to avoid data leakage\nunique_patient_ids = tf_dataset['Patient ID'].unique()\nnp.random.seed(42)\nnp.random.shuffle(unique_patient_ids)\n\nsplit_idx = int(0.8 * len(unique_patient_ids))\ntrain_patient_ids = unique_patient_ids[:split_idx]\nvalidation_patient_ids = unique_patient_ids[split_idx:]\n\ntrain_df = tf_dataset[tf_dataset['Patient ID'].isin(train_patient_ids)]\nvalidation_df = tf_dataset[tf_dataset['Patient ID'].isin(validation_patient_ids)]\n\ndef parse_image(filename, label):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_png(image, channels=1)\n    image = tf.image.resize(image, [240, 240])\n    image = image / 255.0\n    label = tf.cast(label, dtype=tf.float32)\n    return image, label\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_df['Image Path'].values, np.vstack(train_df['Label'].values)))\ntrain_dataset = train_dataset.map(parse_image).shuffle(buffer_size=1000).batch(32)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((validation_df['Image Path'].values, np.vstack(validation_df['Label'].values)))\nvalidation_dataset = validation_dataset.map(parse_image).batch(32)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:44:51.148675Z","iopub.execute_input":"2023-12-28T13:44:51.149280Z","iopub.status.idle":"2023-12-28T13:47:26.788414Z","shell.execute_reply.started":"2023-12-28T13:44:51.149244Z","shell.execute_reply":"2023-12-28T13:47:26.787506Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:47:26.793777Z","iopub.execute_input":"2023-12-28T13:47:26.794218Z","iopub.status.idle":"2023-12-28T13:47:26.914237Z","shell.execute_reply.started":"2023-12-28T13:47:26.794182Z","shell.execute_reply":"2023-12-28T13:47:26.913526Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_labels = data_entry['Finding Labels'].str.split('|').explode().unique()\nnum_classes = len(all_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:47:59.207697Z","iopub.execute_input":"2023-12-28T13:47:59.208447Z","iopub.status.idle":"2023-12-28T13:47:59.543240Z","shell.execute_reply.started":"2023-12-28T13:47:59.208411Z","shell.execute_reply":"2023-12-28T13:47:59.542201Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\"\"\"x = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='SAME')(inputs)\nx = Conv2D(64, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(64, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\nx = Conv2D(32, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(32, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(32, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(32, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs= keras.Input(shape=(240, 240,1))\n\n\nx = Conv2D(128, kernel_size=(3, 3), activation='relu',padding='SAME')(inputs)\nx = Conv2D(128, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(64, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\n\nx = Conv2D(32, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(32, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(16, kernel_size=(3, 3), activation='relu',padding='SAME')(x)\nx = Conv2D(16, kernel_size=(3, 3),padding='SAME')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)\n\n\nx = Flatten(name='flatten')(x)\nx = Dense(units=300, activation='relu')(x)\noutputs = Dense(units=num_classes, activation='sigmoid')(x)\nmodel= keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:18.881053Z","iopub.execute_input":"2023-12-28T13:48:18.881860Z","iopub.status.idle":"2023-12-28T13:48:19.160983Z","shell.execute_reply.started":"2023-12-28T13:48:18.881825Z","shell.execute_reply":"2023-12-28T13:48:19.159964Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"all_labels","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:23.856095Z","iopub.execute_input":"2023-12-28T13:48:23.856757Z","iopub.status.idle":"2023-12-28T13:48:23.863070Z","shell.execute_reply.started":"2023-12-28T13:48:23.856719Z","shell.execute_reply":"2023-12-28T13:48:23.862119Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['Cardiomegaly', 'Emphysema', 'Effusion', 'No Finding', 'Hernia',\n       'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax',\n       'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema',\n       'Consolidation'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:25.881006Z","iopub.execute_input":"2023-12-28T13:48:25.881867Z","iopub.status.idle":"2023-12-28T13:48:25.886937Z","shell.execute_reply.started":"2023-12-28T13:48:25.881832Z","shell.execute_reply":"2023-12-28T13:48:25.885780Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n\ncsv_file_path = '/kaggle/input/data/Data_Entry_2017.csv'\ndata_entry = pd.read_csv(csv_file_path)\n\nlabels = data_entry['Finding Labels'].str.split('|').tolist()\n\nmlb = MultiLabelBinarizer()\nmlb.fit(labels)\n\nbinary_labels = mlb.transform(labels)\n\nclass_counts = binary_labels.sum(axis=0)\nn_samples = len(labels)\n\nclass_weights = (n_samples / class_counts)\n\nmin_weight = min(class_weights)\nclass_weights_normalized = class_weights / min_weight\n\nclass_weights = {i: weight for i, weight in enumerate(class_weights_normalized)}\n\nclass_weights\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:29.288251Z","iopub.execute_input":"2023-12-28T13:48:29.288586Z","iopub.status.idle":"2023-12-28T13:48:29.931961Z","shell.execute_reply.started":"2023-12-28T13:48:29.288554Z","shell.execute_reply":"2023-12-28T13:48:29.930985Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{0: 5.221991521757937,\n 1: 21.743876080691642,\n 2: 12.93357617313049,\n 3: 26.209726443768997,\n 4: 4.532627468649094,\n 5: 23.99085850556439,\n 6: 35.801304863582445,\n 7: 265.90748898678413,\n 8: 3.0341308937368052,\n 9: 10.439467312348668,\n 10: 1.0,\n 11: 9.534196809350814,\n 12: 17.831905465288035,\n 13: 42.18099231306779,\n 14: 11.384571859675594}"},"metadata":{}}]},{"cell_type":"code","source":"class_counts","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:32.997061Z","iopub.execute_input":"2023-12-28T13:48:32.997427Z","iopub.status.idle":"2023-12-28T13:48:33.005829Z","shell.execute_reply.started":"2023-12-28T13:48:32.997395Z","shell.execute_reply":"2023-12-28T13:48:33.004845Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([11559,  2776,  4667,  2303, 13317,  2516,  1686,   227, 19894,\n        5782, 60361,  6331,  3385,  1431,  5302])"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.BinaryCrossentropy(),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:34.664133Z","iopub.execute_input":"2023-12-28T13:48:34.664994Z","iopub.status.idle":"2023-12-28T13:48:34.685497Z","shell.execute_reply.started":"2023-12-28T13:48:34.664938Z","shell.execute_reply":"2023-12-28T13:48:34.684632Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_early_stopping():\n    \n    return tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n     \nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                                  patience=6, min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:36.239294Z","iopub.execute_input":"2023-12-28T13:48:36.240147Z","iopub.status.idle":"2023-12-28T13:48:36.244971Z","shell.execute_reply.started":"2023-12-28T13:48:36.240112Z","shell.execute_reply":"2023-12-28T13:48:36.243972Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:41.262325Z","iopub.execute_input":"2023-12-28T13:48:41.263077Z","iopub.status.idle":"2023-12-28T13:48:41.267075Z","shell.execute_reply.started":"2023-12-28T13:48:41.263043Z","shell.execute_reply":"2023-12-28T13:48:41.265913Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = \"./checkpoint\"\ncheckpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:42.517013Z","iopub.execute_input":"2023-12-28T13:48:42.517388Z","iopub.status.idle":"2023-12-28T13:48:42.522423Z","shell.execute_reply.started":"2023-12-28T13:48:42.517359Z","shell.execute_reply":"2023-12-28T13:48:42.521280Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"early_stopping = get_early_stopping()\n\ncallbacks = [checkpoint_callback, reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:49.492455Z","iopub.execute_input":"2023-12-28T13:48:49.492847Z","iopub.status.idle":"2023-12-28T13:48:49.497575Z","shell.execute_reply.started":"2023-12-28T13:48:49.492816Z","shell.execute_reply":"2023-12-28T13:48:49.496558Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=validation_dataset, batch_size=32, epochs=30,\n                    class_weight=class_weights, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:48:51.695587Z","iopub.execute_input":"2023-12-28T13:48:51.696463Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-12-28 13:48:53.712680: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"2804/2804 [==============================] - 2293s 807ms/step - loss: 1.6555 - accuracy: 0.1333 - val_loss: 0.2869 - val_accuracy: 0.1537 - lr: 0.0010\nEpoch 2/30\n2804/2804 [==============================] - 2239s 796ms/step - loss: 1.5986 - accuracy: 0.1597 - val_loss: 0.2697 - val_accuracy: 0.2059 - lr: 0.0010\nEpoch 3/30\n2804/2804 [==============================] - ETA: 0s - loss: 1.5850 - accuracy: 0.1744","output_type":"stream"}]}]}